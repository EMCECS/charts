#
# Copyright Â© [2020] Dell Inc. or its subsidiaries.
# All Rights Reserved.
#
# This software contains the intellectual property of Dell Inc.
# or is licensed to Dell Inc. from third parties. Use of this
# software and the intellectual property contained therein is expressly
# limited to the terms and conditions of the License Agreement under which
# it is provided by or on behalf of Dell Inc. or its subsidiaries.
#
#

## Default values.yaml for Monitoring
## This is a YAML-formatted file.
---
global:
  rsyslog_uds_dir: "/var/run/rsyslog"
  rsyslog_uds_filename: "rsyslog.socket"
  use_vault_for_ssl: false
  tls_enabled: false
  telegraf_tls_enabled: false
  # communication_scheme defined separately from tls_enabled as found no way to make conditional set in values.yaml
  communication_scheme: http
  influxdb_replicas: 1

cert:
  enabled: true
influxdb:
  persistence:
    storageClassName: "baremetal-csi-sc-ssdlvg"
    hostpath: true
grafana:
  config:
    dashboards_dir: "dashboards/ecs_external"
    home_dashboard: "Process Health - Overview"
throttler:
  config:
    cq_dir: "cq/ecs_external"
telegraf:
  service:
    type: LoadBalancer
    extra_bindings:
      - name: prom
        port: 9273
        targetPort: 9273
      - name: extmon
        port: 18086
        targetPort: 18086
  config:
    influxdb_inputs_enabled: false
    ext_outputs:
      - prometheus_client:
          listen: ":9273"
          expiration_interval: "5m"
    outputs:
      - influxdb:
          insecure_skip_verify: true
          skip_database_creation: true
          timeout: "30s"
          database: "monitoring_main"
          retention_policy: "default"
          namepass:
            - "*_IO_Statistics_data_*"
            - "cm_BTREE_GC_Statistics*"
            - "cm_Chunk_Statistics*"
            - "cm_EC_Statistics*"
            - "cm_REPO_GC_Statistics*"
            - "sr_REPO_GC_Statistics*"
            - "cm_Recover_Statistics*"
            - "cm_Rebalance_Statistics*"
            - "ssm_sstable_SSTable*"
            - "statDataHead_performance*"
            - "blob_SSDReadCache_Stats"
      - influxdb:
          insecure_skip_verify: true
          skip_database_creation: true
          timeout: "30s"
          database: "monitoring_op"
          retention_policy: "default"
          namepass:
            - "dtquery_dt_*"
            - "*_stat_client_performance"
            - "vnestStat_btree"
            - "sr_JournalParser_GC_RG_DT"
            - "sr_ObjectGC_CAS_RG"
            - "tsdb_*"
            - "cquerier_*"
            - "inventory_*"
            - "kubernetes_*"
            - "mem"
            - "swap"
            - "cpu"
            - "processes"
            - "linux_sysctl_fs"
            - "system"
            - "nstat"
      - influxdb:
          insecure_skip_verify: true
          skip_database_creation: true
          timeout: "30s"
          database: "monitoring_last"
          retention_policy: "default"
          namepass:
            - "vnestStat_performance_*"
            - "vnestStat_membership_*"
            - "*_Process_status"
            - "resource_EKM_EKMServer"
            - "eventsvc_Alerts_DT"
            - "sr_ObjectGC_CAS_BUCKET_DT_Blob"
            - "sr_ObjectGC_CAS_BUCKET_DT_Reflection"
            - "dtquery_cmf"
            - "mm_topn_bucket_by_obj_size_place"
            - "mm_topn_bucket_by_obj_count_place"
      - influxdb:
          insecure_skip_verify: true
          skip_database_creation: true
          timeout: "30s"
          database: "monitoring_vdc"
          retention_policy: "default"
          # host and node_id are removed because CQs from several nodes can write same data (even if not simultaneously)
          tagexclude: ["host", "node_id"]
          namepass: ["cq_*"]
    inputs:
      # Influx HTTP write listener
      - influxdb_listener:
          ## Address and port to host HTTP listener on
          # redefine to 11102 when tls is enabled
          service_address: ":11002"
          ## maximum duration before timing out read of the request
          read_timeout: "30s"
          ## maximum duration before timing out write of the response
          write_timeout: "30s"
      # Influx HTTP write listener
      - influxdb_listener:
          ## Address and port to host HTTP listener on
          service_address: ":18086"
          ## maximum duration before timing out read of the request
          read_timeout: "30s"
          ## maximum duration before timing out write of the response
          write_timeout: "30s"
      # Collect statistics about itself
      - internal:
          interval: "300s"
          collect_memstats: true
          name_prefix: "tsdb_telegraf_"
          tags:
            tag: "system"
            host: "$HOSTNAME"
telegraf-prom:
  serviceAccount:
    create: true
  rbac:
    # Specifies whether RBAC resources should be created
    create: true
    # Create only for the release namespace or cluster wide (Role vs ClusterRole)
    clusterWide: false
    # Rules for the created rule
    rules:
      # When using the prometheus input to scrape all pods you need extra rules set to the ClusterRole to be
      # able to scan the pods for scraping labels. The following rules have been taken from:
      # https://github.com/helm/charts/blob/master/stable/prometheus/templates/server-clusterrole.yaml#L8-L46
      - apiGroups:
          - ""
        resources:
          - pods
        verbs:
          - get
          - list
          - watch
  replicaCount: 1
  config:
    outputs:
      - influxdb:
          insecure_skip_verify: true
          skip_database_creation: true
          timeout: "30s"
          database: "monitoring_op"
          retention_policy: "default"
          namepass:
            - "tsdb_fluxd_http_api_request_duration_seconds"
            - "tsdb_fluxd_http_api_requests_total"
            - "tsdb_fluxd_host_state_change_total"
            - "tsdb_fluxd_host_state"
            - "tsdb_fluxd_host_selected"
            - "tsdb_fluxd_host_selection_failed"
            - "tsdb_fluxd_hl_*"
            - "tsdb_fluxd_query_control_executing_duration_seconds"
            - "tsdb_fluxd_http_lb_request_forwarded"
            - "tsdb_fluxd_query_control_panics_total"
            - "tsdb_influxdb"
            - "tsdb_influxdb_database"
            - "tsdb_influxdb_queryExecutor"
            - "tsdb_telegraf_internal_gather"
            - "tsdb_telegraf_internal_write"
            - "cquerier_*"
    inputs:
      # Collect statistics about itself
      - internal:
          interval: "$COLLECTION_INTERVAL"
          collect_memstats: true
          name_prefix: "tsdb_telegraf_"
          tags:
            tag: "system"
            host: "$HOSTNAME"
      - prometheus:
          interval: "$COLLECTION_INTERVAL"
          name_prefix: "tsdb_fluxd_"
          bearer_token: "/var/run/secrets/kubernetes.io/serviceaccount/token"
          monitor_kubernetes_pods: true
          monitor_kubernetes_pods_namespace: "{{ .Release.Namespace }}"
          kubernetes_label_selector: "app.kubernetes.io/name={{ .Release.Name }}-fluxd"
          insecure_skip_verify: true
          tags:
            tag: "system"
      - prometheus:
          interval: "$COLLECTION_INTERVAL"
          kubernetes_services:
            - "{{ .Values.global.communication_scheme }}://{{ .Release.Name }}-throttler.{{ .Release.Namespace }}.svc.cluster.local:18094/metrics"
          monitor_kubernetes_pods: false
          insecure_skip_verify: true
          tags:
            tag: "system"
            host: "throttler"
    processors:
      #
      # Drop 'host' & 'node_id' tags to reduce cardinality
      # * for DT-related metrics
      # * for cluster-wide metrics which may be reported
      #     from different nodes (when master moves)
      #
      - override:
          namepass:
            - "tsdb_influxdb_httpd"
          tagexclude: ["node_id", "ip"]

prometheus:
  server:
    enabled: true
    statefulSet:
      enabled: false
    persistentVolume:
      enabled: false
    retention: "5d"
    alertmanagers:
      - static_configs:
          - targets:
              - "ext-monitoring-prometheus-alertmanager.ext-monitor.svc.cluster.local:80"

  alertmanager:
    enabled: true
    persistentVolume:
      enabled: false

  nodeExporter:
    enabled: false
  pushgateway:
    enabled: false
  kubeStateMetrics:
    enabled: false

  serverFiles:
    ## Alerts configuration
    ## Ref: https://prometheus.io/docs/prometheus/latest/configuration/alerting_rules/
    alerting_rules.yml: {}

    prometheus.yml:
      rule_files:
        - /etc/config/recording_rules.yml
        - /etc/config/alerting_rules.yml

      scrape_configs:
        - job_name: prometheus
          static_configs:
            - targets:
                - localhost:9090

        - job_name: telegraf
          static_configs:
            - targets:
                - ext-monitoring-telegraf.ext-monitor.svc.cluster.local:9273
